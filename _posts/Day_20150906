1. Exchange: fanout, direct, topic
fanout: 群发
direct: 通过一个route key， 可以将消息分类，分给不同的队列, 如只有严重错误才存储，其它消息只是显示到屏上
topic: route key可以是一个复杂的形式，多个条件

Spark::
1. 环境 
Spark不需要hadoop就能运行， 但是实际上需要Hadoop的运行环境
1）hadoop 2.7的没有找到windows下的dll，2.6有：https://github.com/vkovalchuk/hadoop-2.6.0-windows
下载下来后，在环境变量中增加HADOOP_HOME：解压之后的文件夹
2）java:
需要安装java, 就安装Java se吧, 最后不要有空格
安装包后增加环境变量：
JAVA_HOME:c:\java (jre的路径)

2. 使用PYSpark Shell
定位到Spark目录，运行bin\pyspark，如果没有出错信息，则表示正常

3. 简单例子
lines = sc.textFile("readme.md")
line.count() //将输出行数

pythonLines = lines.filter(lamda line: 'Python' in lines)

pythonLines.count() //3

pythonLines.first() //

4. spark program work as follows:
filter等为transfomation
first/count等为action

a. 读取数据并创建一个Rdd
b. 创建一个新的Rdd，使用filter等transformations方法
c. 判断是否需要缓存Rdd，.persist() or cache(), 因为每一个action都是需要重新运算rdd的，rdd是延迟执行的，只有当action运行时才会运行
c. 使用first/count等action计算最终值 

5. Transformation/Actions
transformations: 对RDD进行操作（filter/map）, 返回一个RDD
actions: 返回除RDD外的类型(count/first)

两个Action得出的结果可以使用union操作

6. parallelize, map, flatMap, filter
filter: 过滤
map: 对数组中的每个数字对待处理后返回新对象
e.g. [2,3,4] after map: lambda x: x=x*x 
flatMap: 不好描述, 看代码
lines = sc.parallelize(["hello world","hi"])
worlds = lines.flatMap(lambda line: line.split(" "))
for w in worlds.collect(): print w
//必须对worlds调用collect方法才能转换成集合，才能执行遍历方法

7. combineByKey(func1,func2,func3)
e.g.
partition 1
coffee,1
coffee,2
panda,1

partition 2
panda 9

nums.combineByKey((lambda x: (x,1)),
					(lambda x,y: (x[0]+y,x[1]+1),
					(lambda x,y: (x[0]+y[0],x[1]+y[1])))

解析：分区进行partition1中coffee,1先计算，没有这个key, 所以使用func1, agg['coffee'] = (1,1);第二次碰到coffee时，已经存在，使用func2, x为(1,1), y为2， 结果为(3,2)


8. spark通过jdbc与oracle相连
a. 在conf\spark-env.sh中配置SPARK_CLASSPATH=JDBD.DRIVER
JDBC DRIVER在oracle client\lib\jdbc下找

9. 运行spark下的example 
如：wordcount.py
bin\spark-submit wordcount.py readme.md

10. spark连接sql server/oracle
sqlserver:
a.使用jdbc 4.2.jar, 
b. spark-defaults.conf,注意斜杠
spark.driver.extraClassPath C:\\Java\\jdbc\\sqljdbc_4.2\\enu\\sqljdbc42.jar
spark.executor.extraClassPath C:\\Java\\jdbc\\sqljdbc_4.2\\enu\\sqljdbc42.jar
c.
df = sqlContext.load(source="jdbc", url="jdbc:sqlserver://10.61.43.236:1433;DatabaseName=EveryDay;user=sa;password=Sa@123456", dbtable="EmsAll",driver="com.microsoft.sqlserver.jdbc.SQLServerDriver")
	df.show()
	df.groupBy("Ems").count().show()
	
11. spark cluster in windows
bin\spark-class.cmd org.apache.spark.deploy.master.Master
bin\spark-class.cmd org.apache.spark.deploy.worker.Worker spark://mywin.mydomain.com:7077

application:
conf = SparkConf().setMaster("spark url").setAppName("My app")
sc = SparkContext(conf = conf)


win7 64bit不能使用sqljdbc4.2, sqljdbc4可以使用
目前来看，cluster与slave的关系为： slave使用的配置为cluster的配置，如果与sql server相连，sql server的driver是由cluster下定义的，那么这里有个问题，如果我的cluster是linux, slave是windows，那么这个文件路径如何处理呢？
另外：spark-defaults.conf必须开启日志才行，不然会报错:
【15/07/07 17:01:25 WARN ReliableDeliverySupervisor: Association with remote system [akka.tcp://sparkExecutor@10.64.134.165:56336] has failed, address is now gated for [5000] ms. Reason is: [Disassociated]】如果开启日志，则不会有这个警告了，何解！？

day:20150526.
1. npm install时指定vs的版本
--msvs_version=2012

windows create .nrcm
可以的名字后多输入一个.

2. app.use(express.static('public'));
注意：在引用的时候如果public下面还有文件夹
如：
server.js
public 
	--js
		app.js
	--img
	--view
		index.html

那么index.html的引用js的位置为js/app.js
完整地址为：localost:8080/js/app.js


express.static('public')： 这里的意思应该是指静态文件将在localhost:8080（指代public文件夹）下去找


3. background task:
不想安装windows service, 只想在web的后面默默的执行一些任务，如何更好的实现它呢？
Orchard有一个background task.
http://www.hanselman.com/blog/HowToRunBackgroundTasksInASPNET.aspx
hangfire
	
4. js template 问题
jsrender在渲染2000条时需要10s左右

1. kendoui 所有控件均可通过form.sumbit传回后台，不需要特殊处理
但在js上要获取kendo控件的值，必须这样用：
var stationValue = $("#StationName").data("kendoDropDownList").value();

2. form serialize
a. 一般情况下只需要使用form.serializeArray()即可
b. 有时某些控件只接受object，这样就需要转换，要考虑数组情况
http://stackoverflow.com/questions/11419298/html-form-array-to-json

$.fn.serializeObject = function()
{
    var o = {};
    var a = this.serializeArray();
    $.each(a, function() {
        if (o[this.name] !== undefined) {
            if (!o[this.name].push) {
                o[this.name] = [o[this.name]];
            }
            o[this.name].push(this.value || '');
        } else {
            o[this.name] = this.value || ''; //不能只写这一行， 否则碰到需要回传数组对象时无法处理
        }
    });
    return o;
};

3. 遍历javascript object 
Taken from jQuery docs (http://docs.jquery.com/Utilities/jQuery.each):

var arr = [ "one", "two", "three", "four", "five" ];
var obj = { one:1, two:2, three:3, four:4, five:5 };

jQuery.each(arr, function() {
  $("#" + this).text("My id is " + this + ".");
  return (this != "four"); // will stop running to skip "five"
});

jQuery.each(obj, function(i, val) {
  $("#" + i).append(document.createTextNode(" - " + val));
});

4. moment.js
date format momStart.format("YYYY-MM-DD HH:00");
,判断某一时间是否一个范围内(moment.range.js)
如何更快的得到一段时间范围内的所有时间?
加小时：.add(1, "h");

5. jsrender
数据源为：var colDate = [{"strDate":"2013/3/2"},{"strDate":"2013/3/3"}]
window.app = {
	dataarr:colDate
};
js template:
{{for datearr}}
    <th colspan="2">{{>~format(strDate,"dateFormat")}}</th>
{{/for}}
这里要格式化日期：在jsrender的基础上扩展方法
 $.views.helpers({
        format: function (val, dateType) {
            if (dateType == "dateFormat") {
                return moment(val).format("YYYY-MM-DD");
            }
            else if (dateType == "timeFormat") {
                return moment(val).format("HH:00");
            }
            return moment(val).format("YYYY-MM-DD");
        }
    });
6. 两个日期相差多久
可以将两个日期相减得到毫秒数，然后再转成相应格式
 var difference = (endDate - startDate) / (86400000 * 1);
 如果大于1天，则difference会超过1
